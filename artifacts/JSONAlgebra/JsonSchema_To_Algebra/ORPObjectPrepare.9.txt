/f1984 interessante

/*
rootdef "x" = {
    ref("y"),
    ref("z")
},
def "y" = mof(12),
def "z" = mof(3),
def "not_y" = notMof(12),
def "not_z" = notMof(3),
def "i" = {
    ref("y"),
    ref("z")
},
def "base" = {ref("i"),mof(12)},
def "non_x" = anyOf[
	ref("not_y"),
	ref("not_z")
]
*/


/* In order to split the RList, we first transform each Request (p:A) into a pair
   p, {(p:A)}. When we generate an intersection pattern, we keep track of all the
   original requests that are its ancestors.
   Then, the function rewritePatternReqs, will explode each pair (p, {r1,...,rn})
   into all the different 2^n subcases
*/
void splitOriginalRList(List<WitnessAssertion> list) {
	//modifica coMatrix  PatterReqs prList = new;
  for ( req : list ) { prList.add(req.getKey(),createSingleton(req); }
  PatternReq splitList = splitRList(prList,0,coMatrix);
  rewritePatternReqs(splitList);
}

/* Splits the elements of list from the one with index "index"
   and returns the result of this operation. 
   To this aim, it first splits the elements from index+1 onwards (the tail), and then it takes 
   the element of position index, and it "reduces" it against all elements of the tail
*/
private List<PatternReqs> splitRlist(List<PatternReqs> list, int index, xxx coList) throws WitnessException {
        if(list.size() == index) return list;
        List<PatternReqs> expandedTail = splitRlist(list, index+1, coList);
        Map.Entry<WitnessProperty, List<PatternReqs>> subHead_reducedExpandedTail
	                = reduceReqWithList((WitnessProperty) list.get(index), expandedTail, index, coList);

        if(subHead_reducedExpandedTail.getKey().getKey().isEmpty())
            return subHead_reducedExpandedTail.getValue();
        else{
            subHead_reducedExpandedTail.getValue().add(subHead_reducedExpandedTail.getKey());
            return subHead_reducedExpandedTail.getValue();
        }
    }


/** Returns a pair (PatternReqs,NewList) obtained by reducing list from position index onwards, and ignoring the
  first part
  A PatternReqs is a pair (pattern-List Of Requests) that indicates that, for each req in List Of Requests, 
  its ORP should contain one element whose pattern is "pattern"
  Reducing "req" with "head" means that "head" is split into "head and req" and "head minus req",
  while req is reduced to what remais (req-head).  
  Reduction only combines two elements that are compatible according to coList, and updates the coList,
  but this is just an optimization in order to reduce the amount of pattern intersections to compute
  coList is just an optimization */
private Map.Entry<PatternReqs, List<PatternReqs>>
   reduceReqWithList(PatternReqs req, List<PatternReqs> list, int index,xxx coList) throws WitnessException {
        if(index == list.size()) return new AbstractMap.SimpleEntry<>(req, new LinkedList<>());

        Map.Entry<PatternReqs, List<PatternReqs>> subReq_reducedTail = reduceReqWithList(req, list, index+1, coList);
        PatternReqs subReq = subReq_reducedTail.getKey();
	List<PatternReqs> reducedTail = subReq_reducedTail.getValue();

        /* if dom(subReq) is already empty there is no reduction left to perform */
        PatternReqs head = (PatternReqs) list.get(index);
	ComplexPattern subReqPatt = subReq.getKey();
        if(  (not-compatible(subReq with head according to coList)  || (subReqPatt.isEmpty() )  ) {  //se contenuta la coppia subReq-head
            LinkedList<PatternReqs> returnList = new LinkedList<>(reducedTail); // do we really need this?
            returnList.add(head);
            return new AbstractMap.SimpleEntry<>(subReq, returnList);
        }

        /* if we arrive here, then subReq is not empty and it is coList-compatible with head */
        coList.removePair(subReq,head);  
        ComplexPattern intersection = subReqPatt.intersect(head.getKey());

        /* if there is not intersection, we can stop here */
        if(intersection.isEmpty){
            LinkedList<PatternReqs> returnList = new LinkedList<>(reducedTail); // do we really need this?
            returnList.add(head);
            return new AbstractMap.SimpleEntry<>(subReq, returnList);
        }

        /* otherwise, we create the intersect fragment */
	PatternReqs intersectReq = new PatternReqs(intersection, head.getValue().clone().addAll(head.getValue()));
        LinkedList<PatternReqs> newReducedList  = new LinkedList<>(reducedTail); // do we really need this?
	                                                                         //should we do this at the beginning??
	newReducedList.add(intersectReq);
        coList.addPairs(intersectReq, coList.compWith(subReq).intersect(coList.compWith(head))); // addPairs(x,X): all pairs (x,y) con y in X

//nuova comatrix di PatternReq.
	//compWith: cerco proprio l'oggetto nella comatrix

        /* we also reduce req - the reducedReq may have empty pattern*/
        ComplexPattern reqMinHead = subReqPatt.minus(head.getKey());
        PatternReqs newSubReq =new PatternReqs(reqMinHead, subReq.getValue()); // req minus getValue is the reduced req
        if (reqMinHead.isNotEmpty()) { // no need to do this is reqMinHead is empty
	   coList.addPairs(newSubReq, coList.compWith(subReq));
        }

        /* finally, we also generate headMinReq, in case it is not empty */
        ComplexPattern headMinReq = head.getKey().minus(subReqPatt);
        if(headMinReq.isNotEmpty()) {
            PatternReqs headMinReqReq = new PatternReqs(headMinReq, head.getValue());
	    newReducedList.add(headMinReqReq); // right minus left : rightSchema goes in the list
	    coList.addPairs(headMinReqReq, coList.compWith(head));
        }
	
        coList.removePairsWith(head);
        coList.removePairsWith(subReq);

        return new AbstractMap.SimpleEntry<>(newSubReq, newReducedList);
    }

rewritePatternReqsList (List<PatternReqs> list) {
  List<...> oldRequests = getAllOldRequests(); ---
  for ( pReqs : list ) {
    rewritePatternReqs(pReqs);
  }
  for ( oldReq : oldRequests ) {
    oldReq.deconnect(oldReq.ORPList());
  }
}

/* a PatternReq  p : (p1:A1,...,pn:An) is here expanded into 2^n distinct cases, one for each
   subset of R1...Rn. 
   For each non-empty subset of (p1:A1,...,pn:An) we build a fragment request that satisfies that subset and 
   does not satisfy any equest out of that subset, hence that fragment will go in all and only the ORPs that
   contain one request of that subset
*/
rewritePatternReqs(Pair<ComplexPattern,List<Request>> reqs {
  ComplexPattern patt = reqs.getKey();
  List<Request> reqList = reqs.getValue();
  if (reqList.size() == 0) { fail??}  // impossible case
  if (reqList.size() == 1 ) {
      NO!!! CLONARE!!!! reqList.get(0).setKey(patt) ;  // just rewrite the pattern part - is this allowed in Java?
       return;
  }
  /* non-trivial set */
  for ( subset : compSubsetsOf(reqList) ) { //subset: we create here a fragment that
                                            //satisfies all and only the assertions in "subset"
                                            //subset is never empty
     AndWitness schema = new AndWitness();   //subset: the set of Ancerstors that are compatible with this fragment
     coSubset = reqList.minus(subset);
     for ( oldReq : subset ) { schema.add(oldReq.getValue()); }         //  schema = schema and schemaOf(oldReq)
     for ( oldReq : coSubset ) { schema.add(oldReq.getValue().not()); } //  schema = schema and not schemaOf(oldReq)
     Request fragment = new Request(patt,schema); //fragment: satisfies subset and fails all assertions in coSubset
     for ( compAncestor : subset ) {            //we put the fragment in all and only the ORPs that contain
         for ( orp : compAncestor.ORPList ) {   //one req that is satisfied 
	        fragment.connect(orp);
	    }
     }
  }
}

/* this is a trivial version that generates all non-empty subsets with no compatibility check */
List<List<Request>> compSubsetsOf(List<Request> reqList) {
  if (reqList.size()=1) { return (createSingleton(reqList)); } // receives { r } and return {{r}}
  Request head = reqList.remove(0); // ?
  List<List<Request>> subsetsNoHead = compSubsetsOf(reqList) // we compute the non-empty subsets of the reqList with no head
  subsetsNoHead.clone();
  for ( subNoHead : subsetsNoHead) {
      returnList.add(subNoHead.add(head))  
  }
  returnList.add(crateSingleton(head)); // subsetsNoHead does not contain the empty set, hence we must add this singleton
  return (returnList);
}

/* Version 2: this one build a list of incompatible pairs, and does not build any subset that contain such pairs */
List<List<Request>> compSubsetsOf(List<Request> reqList) {
  if (reqList.size()=1) { return (createSingleton(reqList)) // receives { r } and return {{r}}
  ExcList excList = createExclusionList(reqList);
  return compSubsetsOf(List<Request> reqList, excList);
}

List<List<Request>> compSubsetsOf(List<Request> reqList, ExcList excList) {
  Request head = reqList.remove(0);
  List<List<Request>> subsetsNoHead = compSubsetsOf(reqList,excList) // we compute the non-empty subsets of the reqList with no head
  List<List<Request>> returnList = subsetsNoHead.clone();
  for ( subNoHead : subsetsNoHead) {
      if (excList.get(head).emptyIntersect(subNoHead)) { // excList.get(head): elements incompatible with head
          returnList.insert(subNoHead.add(head))
      }
  }
  returnList.add(crateSingleton(head)); // subsetsNoHead does not contain the empty set, hence we must add this singleton  
  return (returnList);
}
  
createExclusionList(reqList) {
  ExcList result = new;
  for (i in 0 reqList.size-2) {
     for (j in i+1 reqList.size-1) {
        if (obviouslyIncompatible(reqList.get(i).getValue,reqList.get(j).getValue) {
	   result.addPair(reqList.get(i),reqList.get(j);
	   }
  }
}
